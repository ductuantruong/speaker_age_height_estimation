{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "worse-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from TIMIT.lightning_model_uncertainty_loss import LightningModel\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "geographic-stations",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Downstream] can not import .sv_voxceleb1.expert: No module named 'utility'... Pass.\n",
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "[hubconf] can not import .downstream.timit_phone.hubconf: No module named 'upstream'... Pass.\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/3a990c945fbe378df95598eec534e91ba22a5d9eab0b2f88777a7a696d1344e9\n",
      "for https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/s3prl_env/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `MeanAbsoluteError` was deprecated since v1.3.0 in favor of `torchmetrics.regression.mean_absolute_error.MeanAbsoluteError`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "/notebooks/s3prl_env/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details: #Params = 164364294\t#Trainable Params = 161212422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'checkpoints/epoch=21-step=10779-v26.ckpt'\n",
    "model = LightningModel.load_from_checkpoint(model_checkpoint)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "allied-demonstration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.transformer_encoder_M.layers[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "wooden-interstate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301 1680\n"
     ]
    }
   ],
   "source": [
    "phnFiles = os.listdir('./TIMIT_Dataset/wav_data/phn')\n",
    "testWavFiles = os.listdir('./TIMIT_Dataset/wav_data/TEST')\n",
    "phnFiles.sort()\n",
    "testWavFiles.sort()\n",
    "print(len(phnFiles), len(testWavFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "foreign-creativity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'FADG0_SA1.PHN',\n",
       " 'FADG0_SA2.PHN',\n",
       " 'FADG0_SI1279.PHN',\n",
       " 'FADG0_SI1909.PHN']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phnFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "touched-spirituality",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FADG0_SA1.WAV',\n",
       " 'FADG0_SA2.WAV',\n",
       " 'FADG0_SI1279.WAV',\n",
       " 'FADG0_SI1909.WAV',\n",
       " 'FADG0_SI649.WAV']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testWavFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "jewish-eclipse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPhnWavFiles = []\n",
    "\n",
    "for i,testWavFile in enumerate(testWavFiles):\n",
    "    if((testWavFile[:-4]+'.PHN') in phnFiles):\n",
    "        testPhnWavFiles.append(['./TIMIT_Dataset/wav_data/TEST/'+testWavFile, './TIMIT_Dataset/wav_data/phn/'+testWavFile[:-4]+'.PHN'])\n",
    "len(testPhnWavFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stupid-penny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./TIMIT_Dataset/wav_data/TEST/FADG0_SA1.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SA1.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SA2.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SA2.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SI1279.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SI1279.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SI1909.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SI1909.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SI649.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SI649.PHN']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPhnWavFiles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-belize",
   "metadata": {},
   "source": [
    "# Phone map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moving-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://catalog.ldc.upenn.edu/docs/LDC93S1/PHONCODE.TXT\n",
    "symbolList = [                                      \n",
    "                  'b',          \n",
    "                  'd',          \n",
    "                  'g',          \n",
    "                  'p',          \n",
    "                  't',          \n",
    "                  'k',         \n",
    "                  'dx',         \n",
    "                  'q',          \n",
    "\n",
    "                  'jh',         \n",
    "                  'ch',         \n",
    "\n",
    "                  's',          \n",
    "                  'sh',         \n",
    "                  'z',          \n",
    "                  'zh',         \n",
    "                  'f',          \n",
    "                  'th',         \n",
    "                  'v',           \n",
    "                  'dh',         \n",
    "\n",
    "                  'm',          \n",
    "                  'n',         \n",
    "                  'ng',         \n",
    "                  'em',         \n",
    "                  'en',         \n",
    "                  'eng',        \n",
    "                  'nx',         \n",
    "                             \n",
    "                  'l',          \n",
    "                  'r',          \n",
    "                  'w',          \n",
    "                  'y',          \n",
    "                  'hh',         \n",
    "                  'hv',         \n",
    "                  'el',         \n",
    "                  \n",
    "                  'iy',        \n",
    "                  'ih',          \n",
    "                  'eh',         \n",
    "                  'ey',         \n",
    "                  'ae',         \n",
    "                  'aa',         \n",
    "                  'aw',         \n",
    "                  'ay',         \n",
    "                  'ah',         \n",
    "                  'ao',         \n",
    "                  'oy',         \n",
    "                  'ow',         \n",
    "                  'uh',         \n",
    "                  'uw',         \n",
    "                  'ux',         \n",
    "                  'er',         \n",
    "                  'ax',        \n",
    "                  'ix',        \n",
    "                  'axr',        \n",
    "                  'ax-h',      \n",
    "\n",
    "                  'pau',     \n",
    "                  'epi',     \n",
    "                  'h#',     \n",
    "                  '1',       \n",
    "                  '2', \n",
    "\n",
    "                   'bcl','dcl','gcl','pcl','tck','kcl','tcl']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "tracked-sweden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbolList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "extreme-sailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "annoying-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSymbolInfo(phnFile, selfAttnMatrix):\n",
    "    with open(phnFile) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        lo, hi, symbol = line.split(\" \")\n",
    "        lo = int(lo)\n",
    "        hi = int(hi)\n",
    "        if(symbol[-1] == '\\n'):\n",
    "            symbol = symbol[:-1]\n",
    "        if(symbol == 'h#'):\n",
    "            continue\n",
    "#         print(lo, hi, symbol)\n",
    "        if(symbol not in symbolList):\n",
    "            embed()\n",
    "        assert(symbol in symbolList)\n",
    "        lo_ = lo//320\n",
    "        hi_ = (hi+319)//320\n",
    "        if(torch.isnan(selfAttnMatrix[lo_:hi_,lo_:hi_].mean())):\n",
    "            embed()\n",
    "        symbolCountMap[symbol] += selfAttnMatrix[lo_:hi_,lo_:hi_].mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-mapping",
   "metadata": {},
   "source": [
    "# Making Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "endless-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://catalog.ldc.upenn.edu/docs/LDC93S1/PHONCODE.TXT\n",
    "stopsSymbolList = [                                      \n",
    "                  'b',          \n",
    "                  'd',          \n",
    "                  'g',          \n",
    "                  'p',          \n",
    "                  't',          \n",
    "                  'k',         \n",
    "                  'dx',         \n",
    "                  'q']\n",
    "\n",
    "affricatesSymbolList = [\n",
    "                  'jh']     \n",
    "\n",
    "fricativesSymbolList = [\n",
    "                  's',          \n",
    "                  'sh',         \n",
    "                  'z',          \n",
    "                  'zh',         \n",
    "                  'f',          \n",
    "                  'th',         \n",
    "                  'v',           \n",
    "                  'dh',]     \n",
    "nasalsSymbolList = [\n",
    "                  'm',          \n",
    "                  'n',         \n",
    "                  'ng',         \n",
    "                  'em',         \n",
    "                  'en',         \n",
    "                  'eng',        \n",
    "                  'nx',]       \n",
    "semivowelsGlidesSymbolList = [                        \n",
    "                  'l',          \n",
    "                  'r',          \n",
    "                  'w',          \n",
    "                  'y',          \n",
    "                  'hh',         \n",
    "                  'hv',         \n",
    "                  'el',]      \n",
    "vowelsSymbolList = [            \n",
    "                  'iy',        \n",
    "                  'ih',          \n",
    "                  'eh',         \n",
    "                  'ey',         \n",
    "                  'ae',         \n",
    "                  'aa',         \n",
    "                  'aw',         \n",
    "                  'ay',         \n",
    "                  'ah',         \n",
    "                  'ao',         \n",
    "                  'oy',         \n",
    "                  'ow',         \n",
    "                  'uh',         \n",
    "                  'uw',         \n",
    "                  'ux',         \n",
    "                  'er',         \n",
    "                  'ax',        \n",
    "                  'ix',        \n",
    "                  'axr',        \n",
    "                  'ax-h',]    \n",
    "othersSymbolList = [\n",
    "                  'pau',     \n",
    "                  'epi',     \n",
    "                  'h#',     \n",
    "                  '1',       \n",
    "                  '2' ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "textile-shaft",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset/data_info_height_age.csv')\n",
    "h_mean = df[df['Use'] == 'TRN']['height'].mean()\n",
    "h_std = df[df['Use'] == 'TRN']['height'].std()\n",
    "a_mean = df[df['Use'] == 'TRN']['age'].mean()\n",
    "a_std = df[df['Use'] == 'TRN']['age'].std()\n",
    "df.set_index('ID', inplace=True)\n",
    "gender_dict = {'M' : 0, 'F' : 1}\n",
    "\n",
    "h_mean_male = df[(df['Use'] == 'TRN') & (df['Sex'] == 'M')]['height'].mean()\n",
    "a_mean_male = df[(df['Use'] == 'TRN') & (df['Sex'] == 'M')]['age'].mean()\n",
    "\n",
    "h_mean_female = df[(df['Use'] == 'TRN') & (df['Sex'] == 'F')]['height'].mean()\n",
    "a_mean_female = df[(df['Use'] == 'TRN') & (df['Sex'] == 'F')]['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "established-airplane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.84134969325135 30.393343558282208\n",
      "165.36147058823522 29.80727941176471\n"
     ]
    }
   ],
   "source": [
    "print(h_mean_male, a_mean_male)\n",
    "print(h_mean_female, a_mean_female)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "starting-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "height_pred = []\n",
    "height_true = []\n",
    "age_pred = []\n",
    "age_true = []\n",
    "gender_pred = []\n",
    "gender_true = []\n",
    "\n",
    "for i,testPhnWavFile in enumerate(testPhnWavFiles):\n",
    "    wav, _ = torchaudio.load(testPhnWavFile[0])\n",
    "    wav_len = [wav.shape[1]]\n",
    "    wav = wav.to('cuda')\n",
    "    phnFile = testPhnWavFile[1]\n",
    "    \n",
    "    with open(phnFile) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        lo, hi, symbol = line.split(\" \")\n",
    "        lo = int(lo)\n",
    "        hi = int(hi)\n",
    "        if(symbol[-1] == '\\n'):\n",
    "            symbol = symbol[:-1]\n",
    "        if (symbol in othersSymbolList):\n",
    "            wav[0,lo:hi] = 0\n",
    "    \n",
    "    y_hat_h, y_hat_a, y_hat_g = model(wav, wav_len)\n",
    "    y_hat_h = y_hat_h.to('cpu')\n",
    "    y_hat_a = y_hat_a.to('cpu')\n",
    "    y_hat_g = y_hat_g.to('cpu')\n",
    "    \n",
    "    height_pred.append((y_hat_h*h_std+h_mean).item())\n",
    "    age_pred.append((y_hat_a*a_std+a_mean).item())\n",
    "    gender_pred.append(y_hat_g>0.5)\n",
    "\n",
    "    id = testPhnWavFile[0][30:].split('_')[0][1:]\n",
    "    g_id = testPhnWavFile[0][30:].split('_')[0][0]\n",
    "\n",
    "    y_g = gender_dict[df.loc[id, 'Sex']]\n",
    "    y_h = df.loc[id, 'height']\n",
    "    y_a =  df.loc[id, 'age']\n",
    "    height_true.append(y_h)\n",
    "    age_true.append(y_a)\n",
    "    gender_true.append(y_g)    \n",
    "    \n",
    "#     if(i == 0):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "whole-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.310862375889352 5.584817414419992 5.915792169549828 4.154623309748513\n",
      "6.158481982347664 4.923283308846609 7.51586216541237 5.009144041606358\n"
     ]
    }
   ],
   "source": [
    "female_idx = np.where(np.array(gender_true) == 1)[0].reshape(-1).tolist()\n",
    "male_idx = np.where(np.array(gender_true) == 0)[0].reshape(-1).tolist()\n",
    "\n",
    "height_true = np.array(height_true)\n",
    "height_pred = np.array(height_pred)\n",
    "age_true = np.array(age_true)\n",
    "age_pred = np.array(age_pred)\n",
    "\n",
    "hmae = mean_absolute_error(height_true[male_idx], height_pred[male_idx])\n",
    "hrmse = mean_squared_error(height_true[male_idx], height_pred[male_idx], squared=False)\n",
    "amae = mean_absolute_error(age_true[male_idx], age_pred[male_idx])\n",
    "armse = mean_squared_error(age_true[male_idx], age_pred[male_idx], squared=False)\n",
    "print(hrmse, hmae, armse, amae)\n",
    "\n",
    "hmae = mean_absolute_error(height_true[female_idx], height_pred[female_idx])\n",
    "hrmse = mean_squared_error(height_true[female_idx], height_pred[female_idx], squared=False)\n",
    "amae = mean_absolute_error(age_true[female_idx], age_pred[female_idx])\n",
    "armse = mean_squared_error(age_true[female_idx], age_pred[female_idx], squared=False)\n",
    "print(hrmse, hmae, armse, amae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "successful-deployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7396303  0.21688189 0.36126614 0.2390644  0.37808675 1.\n",
      " 0.04179452]\n"
     ]
    }
   ],
   "source": [
    "categories = ['Stops', 'Affricates', 'Fricatives', 'Nasals', 'Semivowels and Glides', 'Vowels', 'Others']\n",
    "values = np.array([stopsSymbolCount, affricatesSymbolCount, fricativesSymbolCount, nasalsSymbolListCount, semivowelsGlidesSymbolCount, vowelsSymbolCount, othersSymbolCount])\n",
    "values = values/max(values)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "heard-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(categories, values)\n",
    "plt.xlabel(\"Relative importance\")\n",
    "plt.ylabel(\"Types of phone\")\n",
    "plt.title(\"\")\n",
    "plt.savefig('phoneGraph.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cubic-sharing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122898"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "noble-training",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0056, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uncertainty_loss.log_var_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "permanent-europe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0035, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uncertainty_loss.log_var_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "strong-bosnia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0065, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uncertainty_loss.log_var_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-adoption",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl_env",
   "language": "python",
   "name": "s3prl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
