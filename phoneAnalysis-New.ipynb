{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civil-panic",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from TIMIT.lightning_model_uncertainty_loss import LightningModel\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, accuracy_score\n",
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "reliable-blood",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/s3prl_s3prl_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Downstream] can not import .sv_voxceleb1.expert: No module named 'utility'... Pass.\n",
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n",
      "[hubconf] can not import .downstream.timit_phone.hubconf: No module named 'upstream'... Pass.\n",
      "Using cache found in /root/.cache/torch/hub/s3prl_cache/3a990c945fbe378df95598eec534e91ba22a5d9eab0b2f88777a7a696d1344e9\n",
      "for https://dl.fbaipublicfiles.com/fairseq/wav2vec/wav2vec_small.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/notebooks/s3prl_env/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `MeanAbsoluteError` was deprecated since v1.3.0 in favor of `torchmetrics.regression.mean_absolute_error.MeanAbsoluteError`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n",
      "/notebooks/s3prl_env/lib/python3.8/site-packages/deprecate/deprecation.py:115: LightningDeprecationWarning: The `Accuracy` was deprecated since v1.3.0 in favor of `torchmetrics.classification.accuracy.Accuracy`. It will be removed in v1.5.0.\n",
      "  stream(template_mgs % msg_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details: #Params = 164364294\t#Trainable Params = 161212422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = 'checkpoints/epoch=12-step=6369-v3.ckpt'\n",
    "model = LightningModel.load_from_checkpoint(model_checkpoint)\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "swedish-instrumentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.model.transformer_encoder_M.layers[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "solar-church",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6301 1680\n"
     ]
    }
   ],
   "source": [
    "phnFiles = os.listdir('./TIMIT_Dataset/wav_data/phn')\n",
    "testWavFiles = os.listdir('./TIMIT_Dataset/wav_data/TEST')\n",
    "phnFiles.sort()\n",
    "testWavFiles.sort()\n",
    "print(len(phnFiles), len(testWavFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stylish-challenge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'FADG0_SA1.PHN',\n",
       " 'FADG0_SA2.PHN',\n",
       " 'FADG0_SI1279.PHN',\n",
       " 'FADG0_SI1909.PHN']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phnFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "numeric-drama",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FADG0_SA1.WAV',\n",
       " 'FADG0_SA2.WAV',\n",
       " 'FADG0_SI1279.WAV',\n",
       " 'FADG0_SI1909.WAV',\n",
       " 'FADG0_SI649.WAV']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testWavFiles[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranging-rogers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPhnWavFiles = []\n",
    "\n",
    "for i,testWavFile in enumerate(testWavFiles):\n",
    "    if((testWavFile[:-4]+'.PHN') in phnFiles):\n",
    "        testPhnWavFiles.append(['./TIMIT_Dataset/wav_data/TEST/'+testWavFile, './TIMIT_Dataset/wav_data/phn/'+testWavFile[:-4]+'.PHN'])\n",
    "len(testPhnWavFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "advance-russia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['./TIMIT_Dataset/wav_data/TEST/FADG0_SA1.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SA1.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SA2.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SA2.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SI1279.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SI1279.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SI1909.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SI1909.PHN'],\n",
       " ['./TIMIT_Dataset/wav_data/TEST/FADG0_SI649.WAV',\n",
       "  './TIMIT_Dataset/wav_data/phn/FADG0_SI649.PHN']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPhnWavFiles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-forestry",
   "metadata": {},
   "source": [
    "# Phone map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "subject-address",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://catalog.ldc.upenn.edu/docs/LDC93S1/PHONCODE.TXT\n",
    "symbolList = [                                      \n",
    "                  'b',          \n",
    "                  'd',          \n",
    "                  'g',          \n",
    "                  'p',          \n",
    "                  't',          \n",
    "                  'k',         \n",
    "                  'dx',         \n",
    "                  'q',          \n",
    "\n",
    "                  'jh',         \n",
    "                  'ch',         \n",
    "\n",
    "                  's',          \n",
    "                  'sh',         \n",
    "                  'z',          \n",
    "                  'zh',         \n",
    "                  'f',          \n",
    "                  'th',         \n",
    "                  'v',           \n",
    "                  'dh',         \n",
    "\n",
    "                  'm',          \n",
    "                  'n',         \n",
    "                  'ng',         \n",
    "                  'em',         \n",
    "                  'en',         \n",
    "                  'eng',        \n",
    "                  'nx',         \n",
    "                             \n",
    "                  'l',          \n",
    "                  'r',          \n",
    "                  'w',          \n",
    "                  'y',          \n",
    "                  'hh',         \n",
    "                  'hv',         \n",
    "                  'el',         \n",
    "                  \n",
    "                  'iy',        \n",
    "                  'ih',          \n",
    "                  'eh',         \n",
    "                  'ey',         \n",
    "                  'ae',         \n",
    "                  'aa',         \n",
    "                  'aw',         \n",
    "                  'ay',         \n",
    "                  'ah',         \n",
    "                  'ao',         \n",
    "                  'oy',         \n",
    "                  'ow',         \n",
    "                  'uh',         \n",
    "                  'uw',         \n",
    "                  'ux',         \n",
    "                  'er',         \n",
    "                  'ax',        \n",
    "                  'ix',        \n",
    "                  'axr',        \n",
    "                  'ax-h',      \n",
    "\n",
    "                  'pau',     \n",
    "                  'epi',     \n",
    "                  'h#',     \n",
    "                  '1',       \n",
    "                  '2', \n",
    "\n",
    "                   'bcl','dcl','gcl','pcl','tck','kcl','tcl']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "alike-raleigh",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(symbolList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "compact-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "residential-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSymbolInfo(phnFile, selfAttnMatrix):\n",
    "    with open(phnFile) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        lo, hi, symbol = line.split(\" \")\n",
    "        lo = int(lo)\n",
    "        hi = int(hi)\n",
    "        if(symbol[-1] == '\\n'):\n",
    "            symbol = symbol[:-1]\n",
    "        if(symbol == 'h#'):\n",
    "            continue\n",
    "#         print(lo, hi, symbol)\n",
    "        if(symbol not in symbolList):\n",
    "            embed()\n",
    "        assert(symbol in symbolList)\n",
    "        lo_ = lo//320\n",
    "        hi_ = (hi+319)//320\n",
    "        if(torch.isnan(selfAttnMatrix[lo_:hi_,lo_:hi_].mean())):\n",
    "            embed()\n",
    "        symbolCountMap[symbol] += selfAttnMatrix[lo_:hi_,lo_:hi_].mean()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-enlargement",
   "metadata": {},
   "source": [
    "# Making Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "actual-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_M = {}\n",
    "def get_activation_M(name):\n",
    "    def hook(model, input, output):\n",
    "        activation_M[name] = output\n",
    "    return hook\n",
    "\n",
    "activation_F = {}\n",
    "def get_activation_F(name):\n",
    "    def hook(model, input, output):\n",
    "        activation_F[name] = output\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "actual-louisville",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f274652bc70>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.transformer_encoder_M.layers[5].self_attn.register_forward_hook(get_activation_M('attn_M'))\n",
    "model.model.transformer_encoder_F.layers[5].self_attn.register_forward_hook(get_activation_F('attn_F'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "internal-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbolCountMap = {x: 0 for x in symbolList}\n",
    "\n",
    "for i,testPhnWavFile in enumerate(testPhnWavFiles):\n",
    "    wav, _ = torchaudio.load(testPhnWavFile[0])\n",
    "    wav_len = [wav.shape[1]]\n",
    "    wav = wav.to('cuda')\n",
    "    y_hat_h, y_hat_a, y_hat_g = model(wav, wav_len)\n",
    "    y_hat_h = y_hat_h.to('cpu')\n",
    "    y_hat_a = y_hat_a.to('cpu')\n",
    "    y_hat_g = y_hat_g.to('cpu')\n",
    "    \n",
    "    phnFile = testPhnWavFile[1]\n",
    "    \n",
    "    if(y_hat_g>0.5):\n",
    "        activation_F['attn_F']\n",
    "        selfAttnMatrix = activation_F['attn_F'][1][0].detach().cpu()\n",
    "        getSymbolInfo(phnFile, selfAttnMatrix)\n",
    "    else:\n",
    "        activation_M['attn_M']\n",
    "        selfAttnMatrix = activation_M['attn_M'][1][0].detach().cpu()\n",
    "        getSymbolInfo(phnFile, selfAttnMatrix)\n",
    "        \n",
    "#     if(i == 0):\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "rocky-thanks",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': tensor(6.0705),\n",
       " 'd': tensor(8.1648),\n",
       " 'g': tensor(5.1328),\n",
       " 'p': tensor(6.0847),\n",
       " 't': tensor(9.5571),\n",
       " 'k': tensor(11.0887),\n",
       " 'dx': tensor(5.9256),\n",
       " 'q': tensor(7.9589),\n",
       " 'jh': tensor(2.3525),\n",
       " 'ch': tensor(1.6509),\n",
       " 's': tensor(16.7183),\n",
       " 'sh': tensor(4.8877),\n",
       " 'z': tensor(7.9235),\n",
       " 'zh': tensor(0.5042),\n",
       " 'f': tensor(6.0633),\n",
       " 'th': tensor(1.8119),\n",
       " 'v': tensor(4.3701),\n",
       " 'dh': tensor(6.8716),\n",
       " 'm': tensor(10.0100),\n",
       " 'n': tensor(15.6497),\n",
       " 'ng': tensor(2.6711),\n",
       " 'em': tensor(0.2944),\n",
       " 'en': tensor(1.4855),\n",
       " 'eng': tensor(0.0333),\n",
       " 'nx': tensor(2.3813),\n",
       " 'l': tensor(15.4387),\n",
       " 'r': tensor(16.5119),\n",
       " 'w': tensor(8.2950),\n",
       " 'y': tensor(4.2079),\n",
       " 'hh': tensor(2.4482),\n",
       " 'hv': tensor(2.2969),\n",
       " 'el': tensor(2.2406),\n",
       " 'iy': tensor(17.6628),\n",
       " 'ih': tensor(10.7860),\n",
       " 'eh': tensor(9.5202),\n",
       " 'ey': tensor(5.2584),\n",
       " 'ae': tensor(9.5156),\n",
       " 'aa': tensor(7.4007),\n",
       " 'aw': tensor(1.5194),\n",
       " 'ay': tensor(5.7596),\n",
       " 'ah': tensor(5.6051),\n",
       " 'ao': tensor(7.5102),\n",
       " 'oy': tensor(1.9698),\n",
       " 'ow': tensor(5.4652),\n",
       " 'uh': tensor(1.5910),\n",
       " 'uw': tensor(1.0583),\n",
       " 'ux': tensor(3.6575),\n",
       " 'er': tensor(5.2676),\n",
       " 'ax': tensor(8.4309),\n",
       " 'ix': tensor(18.4730),\n",
       " 'axr': tensor(8.8812),\n",
       " 'ax-h': tensor(0.7193),\n",
       " 'pau': tensor(2.2058),\n",
       " 'epi': tensor(3.4804),\n",
       " 'h#': 0,\n",
       " '1': 0,\n",
       " '2': 0,\n",
       " 'bcl': tensor(5.2849),\n",
       " 'dcl': tensor(10.4820),\n",
       " 'gcl': tensor(5.5176),\n",
       " 'pcl': tensor(6.1639),\n",
       " 'tck': 0,\n",
       " 'kcl': tensor(13.1964),\n",
       " 'tcl': tensor(15.0216)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symbolCountMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "rocky-palmer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('symbolCountMap.pkl', 'wb') as f:\n",
    "#     pickle.dump(symbolCountMap, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "instrumental-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('symbolCountMap.pkl', 'rb') as f:\n",
    "#     symbolCountMap = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "least-retirement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://catalog.ldc.upenn.edu/docs/LDC93S1/PHONCODE.TXT\n",
    "stopsSymbolList = [                                      \n",
    "                  'b',          \n",
    "                  'd',          \n",
    "                  'g',          \n",
    "                  'p',          \n",
    "                  't',          \n",
    "                  'k',         \n",
    "                  'dx',         \n",
    "                  'q',  \n",
    "'bcl','dcl','gcl','pcl','tck','kcl']\n",
    "\n",
    "affricatesSymbolList = [\n",
    "                  'jh',         \n",
    "                  'ch','dcl','tcl']     \n",
    "\n",
    "fricativesSymbolList = [\n",
    "                  's',          \n",
    "                  'sh',         \n",
    "                  'z',          \n",
    "                  'zh',         \n",
    "                  'f',          \n",
    "                  'th',         \n",
    "                  'v',           \n",
    "                  'dh',]     \n",
    "nasalsSymbolList = [\n",
    "                  'm',          \n",
    "                  'n',         \n",
    "                  'ng',         \n",
    "                  'em',         \n",
    "                  'en',         \n",
    "                  'eng',        \n",
    "                  'nx',]       \n",
    "semivowelsGlidesSymbolList = [                        \n",
    "                  'l',          \n",
    "                  'r',          \n",
    "                  'w',          \n",
    "                  'y',          \n",
    "                  'hh',         \n",
    "                  'hv',         \n",
    "                  'el',]      \n",
    "vowelsSymbolList = [            \n",
    "                  'iy',        \n",
    "                  'ih',          \n",
    "                  'eh',         \n",
    "                  'ey',         \n",
    "                  'ae',         \n",
    "                  'aa',         \n",
    "                  'aw',         \n",
    "                  'ay',         \n",
    "                  'ah',         \n",
    "                  'ao',         \n",
    "                  'oy',         \n",
    "                  'ow',         \n",
    "                  'uh',         \n",
    "                  'uw',         \n",
    "                  'ux',         \n",
    "                  'er',         \n",
    "                  'ax',        \n",
    "                  'ix',        \n",
    "                  'axr',        \n",
    "                  'ax-h',]    \n",
    "othersSymbolList = [\n",
    "                  'pau',     \n",
    "                  'epi',     \n",
    "                  'h#',     \n",
    "                  '1',       \n",
    "                  '2' ]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "sustainable-philosophy",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopsSymbolCount = 0\n",
    "affricatesSymbolCount = 0\n",
    "fricativesSymbolCount = 0\n",
    "nasalsSymbolListCount = 0\n",
    "semivowelsGlidesSymbolCount = 0\n",
    "vowelsSymbolCount = 0\n",
    "othersSymbolCount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "following-meeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "for (key,value) in symbolCountMap.items():\n",
    "    if(key in stopsSymbolList):\n",
    "        stopsSymbolCount += value\n",
    "    if(key in affricatesSymbolList):\n",
    "        affricatesSymbolCount += value\n",
    "    if(key in fricativesSymbolList):\n",
    "        fricativesSymbolCount += value\n",
    "    if(key in nasalsSymbolList):\n",
    "        nasalsSymbolListCount += value\n",
    "    if(key in semivowelsGlidesSymbolList):\n",
    "        semivowelsGlidesSymbolCount += value\n",
    "    if(key in vowelsSymbolList):\n",
    "        vowelsSymbolCount += value\n",
    "    if(key in othersSymbolList):\n",
    "        othersSymbolCount += value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "corporate-marathon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7396303  0.21688189 0.36126614 0.2390644  0.37808675 1.\n",
      " 0.04179452]\n"
     ]
    }
   ],
   "source": [
    "categories = ['Stops', 'Affricates', 'Fricatives', 'Nasals', 'Semivowels and Glides', 'Vowels', 'Others']\n",
    "values = np.array([stopsSymbolCount, affricatesSymbolCount, fricativesSymbolCount, nasalsSymbolListCount, semivowelsGlidesSymbolCount, vowelsSymbolCount, othersSymbolCount])\n",
    "values = values/max(values)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "complete-notice",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(categories, values)\n",
    "plt.xlabel(\"Relative importance\")\n",
    "plt.ylabel(\"Types of phone\")\n",
    "plt.title(\"\")\n",
    "plt.savefig('phoneGraph.png', dpi=600, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seventh-companion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122898"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "delayed-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0056, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uncertainty_loss.log_var_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "embedded-groove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0035, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uncertainty_loss.log_var_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "verified-spanish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0065, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.uncertainty_loss.log_var_gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-contamination",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "s3prl_env",
   "language": "python",
   "name": "s3prl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
